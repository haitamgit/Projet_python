{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62211be2-99f4-4e84-be65-06faef9eef47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaf4d5a5e5a94b3e8a1e9e10f37a029e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' Recherche dans Discours US (TD8)'), HBox(children=(Label(value='Mots clés :', lay…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Partie3\n",
    "#interfaceComplèteTD8\n",
    "import pandas as pd\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets\n",
    "import re\n",
    "from Corpus import Corpus\n",
    "from Document import Document\n",
    "from SearchEngine import SearchEngine\n",
    "\n",
    "# -------------------------\n",
    "# Charger corpus Discours US\n",
    "# -------------------------\n",
    "df_discours = pd.read_csv(\"data_corpus/discours_us.csv\", sep=\"\\t\")\n",
    "\n",
    "corpus_discours = Corpus(\"Corpus_US\")\n",
    "for idx, row in df_discours.iterrows():\n",
    "    texte = str(row['text'])\n",
    "    phrases = re.split(r'(?<=[.!?])\\s+', texte)\n",
    "    for i, phrase in enumerate(phrases):\n",
    "        doc = Document(\n",
    "            titre=f\"{row['speaker']} - phrase {i+1}\",\n",
    "            auteur=row['speaker'],\n",
    "            date=row['date'],\n",
    "            url=row.get('link', ''),\n",
    "            texte=phrase\n",
    "        )\n",
    "        corpus_discours.add_document(doc)\n",
    "\n",
    "search_engine_discours = SearchEngine(corpus_discours)\n",
    "\n",
    "# -------------------------\n",
    "# Widgets TD8\n",
    "# -------------------------\n",
    "label_td8 = widgets.Label(\" Recherche dans Discours US (TD8)\")\n",
    "\n",
    "text_requete = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Entrez mots clés',\n",
    "    layout=widgets.Layout(width='100%')\n",
    ")\n",
    "\n",
    "slider_topk = widgets.IntSlider(\n",
    "    value=5,\n",
    "    min=1,\n",
    "    max=20,\n",
    "    continuous_update=False,\n",
    "    layout=widgets.Layout(width='100%')\n",
    ")\n",
    "\n",
    "auteurs = sorted(df_discours['speaker'].dropna().unique())\n",
    "dropdown_auteur = widgets.Dropdown(\n",
    "    options=['Tous'] + list(auteurs),\n",
    "    value='Tous',\n",
    "    layout=widgets.Layout(width='100%')\n",
    ")\n",
    "\n",
    "annees = sorted(df_discours['date'].dropna().apply(lambda x: pd.to_datetime(x).year).unique())\n",
    "dropdown_annee = widgets.Dropdown(\n",
    "    options=['Toutes'] + list(annees),\n",
    "    value='Toutes',\n",
    "    layout=widgets.Layout(width='100%')\n",
    ")\n",
    "\n",
    "btn_search_discours = widgets.Button(\n",
    "    description=\"Rechercher\",\n",
    "    button_style='success'\n",
    ")\n",
    "\n",
    "output_td8 = widgets.Output(\n",
    "    layout={'border': '1px solid black', 'height': '300px', 'overflow_y': 'auto'}\n",
    ")\n",
    "\n",
    "\n",
    "LABEL_WIDTH = '250px'\n",
    "\n",
    "ligne_mots_cles = widgets.HBox([\n",
    "    widgets.Label(\"Mots clés :\", layout=widgets.Layout(width=LABEL_WIDTH)),\n",
    "    text_requete\n",
    "])\n",
    "\n",
    "ligne_topk = widgets.HBox([\n",
    "    widgets.Label(\"Nombre d'articles à extraire :\", layout=widgets.Layout(width=LABEL_WIDTH)),\n",
    "  slider_topk\n",
    "])\n",
    "\n",
    "ligne_auteur = widgets.HBox([\n",
    "    widgets.Label(\"Auteur :\", layout=widgets.Layout(width=LABEL_WIDTH)),\n",
    "    dropdown_auteur\n",
    "])\n",
    "\n",
    "ligne_annee = widgets.HBox([\n",
    "    widgets.Label(\"Année :\", layout=widgets.Layout(width=LABEL_WIDTH)),\n",
    "    dropdown_annee\n",
    "])\n",
    "\n",
    "# -------------------------\n",
    "# Fonction de recherche\n",
    "# -------------------------\n",
    "def search_discours(b):\n",
    "    with output_td8:\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        requete_str = text_requete.value.strip()\n",
    "        if not requete_str:\n",
    "            print(\"Veuillez entrer des mots clés.\")\n",
    "            return\n",
    "\n",
    "        top_k = slider_topk.value\n",
    "        resultats = search_engine_discours.search(requete_str, top_k=top_k)\n",
    "\n",
    "        # Filtrer par auteur\n",
    "        if dropdown_auteur.value != 'Tous':\n",
    "            resultats = resultats[resultats['Auteur'] == dropdown_auteur.value]\n",
    "\n",
    "        # Filtrer par année\n",
    "        if dropdown_annee.value != 'Toutes':\n",
    "            resultats = resultats[\n",
    "                resultats['Date'].apply(lambda x: pd.to_datetime(x).year) == dropdown_annee.value\n",
    "            ]\n",
    "\n",
    "        if resultats.empty:\n",
    "            print(\"Aucun résultat trouvé.\")\n",
    "        else:\n",
    "            display(resultats)\n",
    "\n",
    "btn_search_discours.on_click(search_discours)\n",
    "\n",
    "# -------------------------\n",
    "# Interface finale\n",
    "# -------------------------\n",
    "display(widgets.VBox([\n",
    "    label_td8,\n",
    "    ligne_mots_cles,\n",
    "    ligne_topk,\n",
    "    ligne_auteur,\n",
    "    ligne_annee,\n",
    "    btn_search_discours,\n",
    "    output_td8\n",
    "]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be1cfb92-66ca-4a47-b708-1acf2f3d5383",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TD9_10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ad322c0-0311-47bb-a423-44bfc8811f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "842d45bf259d46a2b57e24e6426e57ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Comparaison Reddit / Arxiv'), RadioButtons(description='Type :', options=('Mot com…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# INTERFACETD9/10\n",
    "import pandas as pd\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from Corpus import Corpus\n",
    "from CompareCorpus import CompareCorpus\n",
    "\n",
    "# -------------------------\n",
    "# Stopwords FR + EN\n",
    "# -------------------------\n",
    "stopwords = set([\n",
    "    \"le\",\"la\",\"les\",\"un\",\"une\",\"des\",\"du\",\"de\",\"d'\",\"et\",\"à\",\"au\",\"aux\",\"ce\",\"ces\",\"cet\",\"cette\",\"dans\",\"en\",\n",
    "    \"pour\",\"par\",\"sur\",\"avec\",\"sans\",\"sous\",\"chez\",\"entre\",\"mais\",\"ou\",\"où\",\"donc\",\"or\",\"ni\",\"car\",\"ne\",\"pas\",\n",
    "    \"que\",\"qui\",\"quoi\",\"dont\",\"lorsque\",\"comme\",\"si\",\"être\",\"l\",\"le\",\"la\",\"les\",\"et\",\"de\",\"des\",\"du\",\"un\",\"une\",\n",
    "    \"the\",\"a\",\"an\",\"and\",\"or\",\"but\",\"if\",\"then\",\"for\",\"on\",\"in\",\"at\",\"with\",\"without\",\"by\",\"of\",\"to\",\"from\",\n",
    "    \"up\",\"down\",\"over\",\"under\",\"between\",\"into\",\"about\",\"as\",\"is\",\"are\",\"was\",\"were\",\"be\",\"been\",\"being\",\"he\",\n",
    "    \"she\",\"it\",\"they\",\"them\",\"his\",\"her\",\"its\",\"their\",\"i\",\"you\",\"we\",\"me\",\"him\",\"us\"\n",
    "])\n",
    "\n",
    "# -------------------------\n",
    "# Charger corpus\n",
    "# -------------------------\n",
    "reddit = Corpus(\"Reddit\")\n",
    "reddit.load(\"data_corpus/reddit_fr.csv\")\n",
    "arxiv = Corpus(\"Arxiv\")\n",
    "arxiv.load(\"data_corpus/arxiv_fr.csv\")\n",
    "compare = CompareCorpus(reddit, arxiv)\n",
    "\n",
    "df_reddit = pd.read_csv(\"data_corpus/reddit_fr.csv\")\n",
    "df_arxiv = pd.read_csv(\"data_corpus/arxiv_fr.csv\")\n",
    "\n",
    "# -------------------------\n",
    "# Préparer vocabulaire et mots communs/spécifiques\n",
    "# -------------------------\n",
    "def get_vocab(df):\n",
    "    all_text = ' '.join(df['texte'].astype(str)).lower()\n",
    "    words = re.findall(r'\\b\\w+\\b', all_text)\n",
    "    vocab = {}\n",
    "    for w in words:\n",
    "        if w not in stopwords:\n",
    "            vocab[w] = vocab.get(w,0)+1\n",
    "    return vocab\n",
    "\n",
    "vocab_r = get_vocab(df_reddit)\n",
    "vocab_a = get_vocab(df_arxiv)\n",
    "\n",
    "mots_communs = {w:vocab_r[w]+vocab_a[w] for w in vocab_r if w in vocab_a}\n",
    "mots_spec = {\n",
    "    \"Reddit\": {w:v for w,v in vocab_r.items() if w not in mots_communs},\n",
    "    \"Arxiv\": {w:v for w,v in vocab_a.items() if w not in mots_communs}\n",
    "}\n",
    "\n",
    "# -------------------------\n",
    "# Widgets interface\n",
    "# -------------------------\n",
    "label_titre = widgets.Label(\"Comparaison Reddit / Arxiv\")\n",
    "\n",
    "type_mot = widgets.RadioButtons(\n",
    "    options=[\"Mot commun\", \"Mot spécifique\"],\n",
    "    description=\"Type :\",\n",
    "    value=None\n",
    ")\n",
    "\n",
    "source = widgets.Dropdown(\n",
    "    options=[\"Reddit\",\"Arxiv\",\"Tous\"],\n",
    "    description=\"Source :\"\n",
    ")\n",
    "\n",
    "liste_mots = widgets.Dropdown(description=\"Mot :\")\n",
    "filtre_auteur = widgets.Dropdown(description=\"Auteur :\")\n",
    "filtre_annee = widgets.Dropdown(description=\"Année :\")\n",
    "btn_analyser = widgets.Button(description=\"Analyser le mot\", button_style=\"success\")\n",
    "\n",
    "output = widgets.Output(layout={'border':'1px solid black','height':'700px','overflow_y':'auto'})\n",
    "\n",
    "# -------------------------\n",
    "# Mettre à jour listes mots / auteurs / années\n",
    "# -------------------------\n",
    "def update_liste(*args):\n",
    "\n",
    "    # =========================\n",
    "    # 1. Déterminer la liste de mots\n",
    "    # =========================\n",
    "    if type_mot.value == \"Mot commun\":\n",
    "        mots = sorted(mots_communs.keys())\n",
    "        source.options = [\"Tous\"]\n",
    "        source.value = \"Tous\"\n",
    "        source.disabled = True\n",
    "    else:\n",
    "        source.options = [\"Reddit\", \"Arxiv\"]\n",
    "        source.disabled = False\n",
    "\n",
    "        if source.value == \"Reddit\":\n",
    "            mots = sorted(mots_spec[\"Reddit\"].keys())\n",
    "        elif source.value == \"Arxiv\":\n",
    "            mots = sorted(mots_spec[\"Arxiv\"].keys())\n",
    "        else:\n",
    "            mots = []\n",
    "\n",
    "    # Mise à jour liste des mots\n",
    "    liste_mots.options = mots\n",
    "\n",
    "    # Sélectionner un mot seulement si nécessaire\n",
    "    if mots and liste_mots.value not in mots:\n",
    "        liste_mots.value = mots[0]\n",
    "\n",
    "    # S'il n'y a aucun mot, on vide les filtres\n",
    "    if not liste_mots.value:\n",
    "        filtre_auteur.options = [\"Tous\"]\n",
    "        filtre_annee.options = [\"Toutes\"]\n",
    "        return\n",
    "\n",
    "    mot_sel = liste_mots.value\n",
    "\n",
    "    # =========================\n",
    "    # 2. Filtrer les documents\n",
    "    # =========================\n",
    "    df_r = df_reddit[df_reddit['texte'].str.contains(\n",
    "        rf\"\\b{re.escape(mot_sel)}\\b\", case=False, regex=True, na=False\n",
    "    )]\n",
    "\n",
    "    df_a = df_arxiv[df_arxiv['texte'].str.contains(\n",
    "        rf\"\\b{re.escape(mot_sel)}\\b\", case=False, regex=True, na=False\n",
    "    )]\n",
    "\n",
    "    # =========================\n",
    "    # 3. Auteurs\n",
    "    # =========================\n",
    "    if source.value == \"Reddit\":\n",
    "        auteurs = sorted(df_r['auteur'].dropna().unique())\n",
    "    elif source.value == \"Arxiv\":\n",
    "        auteurs = sorted(df_a['auteur'].dropna().unique())\n",
    "    else:\n",
    "        auteurs = sorted(\n",
    "            set(df_r['auteur'].dropna()) | set(df_a['auteur'].dropna())\n",
    "        )\n",
    "\n",
    "    filtre_auteur.options = [\"Tous\"] + auteurs\n",
    "    filtre_auteur.value = \"Tous\"\n",
    "\n",
    "    # =========================\n",
    "    # 4. Années\n",
    "    # =========================\n",
    "    def get_years(df):\n",
    "        if df.empty:\n",
    "            return set()\n",
    "        return set(pd.to_datetime(df['date'], errors='coerce').dt.year.dropna())\n",
    "\n",
    "    if source.value == \"Reddit\":\n",
    "        annees = sorted(get_years(df_r))\n",
    "    elif source.value == \"Arxiv\":\n",
    "        annees = sorted(get_years(df_a))\n",
    "    else:\n",
    "        annees = sorted(get_years(df_r) | get_years(df_a))\n",
    "\n",
    "    filtre_annee.options = [\"Toutes\"] + [str(a) for a in annees]\n",
    "    filtre_annee.value = \"Toutes\"\n",
    "\n",
    "\n",
    "type_mot.observe(update_liste, names='value')\n",
    "source.observe(update_liste, names='value')\n",
    "liste_mots.observe(update_liste, names='value')\n",
    "\n",
    "# -------------------------\n",
    "# Comptage occurrences par année\n",
    "# -------------------------\n",
    "def count_occurrences(docs, mot):\n",
    "    counts = {}\n",
    "    for doc in docs:\n",
    "        year = pd.to_datetime(doc.date).year\n",
    "        texte = str(doc.texte).lower()\n",
    "        nb = len(re.findall(rf\"\\b{re.escape(mot)}\\b\", texte))\n",
    "        if nb>0:\n",
    "            counts[year] = counts.get(year,0)+nb\n",
    "    return counts\n",
    "\n",
    "# -------------------------\n",
    "# Analyse mot\n",
    "# -------------------------\n",
    "def analyser_mot(b):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        mot_sel = liste_mots.value\n",
    "        if not mot_sel:\n",
    "            print(\"Veuillez sélectionner un mot.\")\n",
    "            return\n",
    "        \n",
    "        auteur_val = None if filtre_auteur.value==\"Tous\" else filtre_auteur.value\n",
    "        annee_val = None if filtre_annee.value==\"Toutes\" else int(filtre_annee.value)\n",
    "        \n",
    "        df_r = df_reddit[df_reddit['texte'].str.contains(rf\"\\b{re.escape(mot_sel)}\\b\", case=False, regex=True)]\n",
    "        df_a = df_arxiv[df_arxiv['texte'].str.contains(rf\"\\b{re.escape(mot_sel)}\\b\", case=False, regex=True)]\n",
    "        \n",
    "        if auteur_val:\n",
    "            df_r = df_r[df_r['auteur']==auteur_val] if not df_r.empty else df_r\n",
    "            df_a = df_a[df_a['auteur']==auteur_val] if not df_a.empty else df_a\n",
    "        if annee_val:\n",
    "            df_r = df_r[pd.to_datetime(df_r['date']).dt.year==annee_val] if not df_r.empty else df_r\n",
    "            df_a = df_a[pd.to_datetime(df_a['date']).dt.year==annee_val] if not df_a.empty else df_a\n",
    "\n",
    "        if df_r.empty and df_a.empty:\n",
    "            print(f\"Aucun document trouvé pour le mot '{mot_sel}'.\")\n",
    "            return\n",
    "\n",
    "        res_r,res_a = compare.analyser_mot(mot_sel)\n",
    "        if not df_r.empty:\n",
    "            df_r = df_r.copy()\n",
    "            df_r['TF'] = res_r['TF']\n",
    "            df_r['IDF'] = res_r['IDF']\n",
    "            df_r['BM25'] = res_r['BM25']\n",
    "        if not df_a.empty:\n",
    "            df_a = df_a.copy()\n",
    "            df_a['TF'] = res_a['TF']\n",
    "            df_a['IDF'] = res_a['IDF']\n",
    "            df_a['BM25'] = res_a['BM25']\n",
    "\n",
    "        if type_mot.value==\"Mot commun\":\n",
    "            if not df_r.empty:\n",
    "                print(f\" Tableau Reddit filtré pour le mot commun '{mot_sel}' :\")\n",
    "                display(df_r[['titre','auteur','date','texte','TF','IDF','BM25']])\n",
    "            if not df_a.empty:\n",
    "                print(f\" Tableau Arxiv filtré pour le mot commun '{mot_sel}' :\")\n",
    "                display(df_a[['titre','auteur','date','texte','TF','IDF','BM25']])\n",
    "        else:\n",
    "            if source.value==\"Reddit\" and not df_r.empty:\n",
    "                print(f\" Tableau Reddit filtré pour le mot spécifique '{mot_sel}' :\")\n",
    "                display(df_r[['titre','auteur','date','texte','TF','IDF','BM25']])\n",
    "            elif source.value==\"Arxiv\" and not df_a.empty:\n",
    "                print(f\" Tableau Arxiv filtré pour le mot spécifique '{mot_sel}' :\")\n",
    "                display(df_a[['titre','auteur','date','texte','TF','IDF','BM25']])\n",
    "\n",
    "        print(\"\\n Interprétation BM25 :\")\n",
    "        print(f\"Reddit : TF={res_r['TF']} | IDF={res_r['IDF']:.3f} | BM25={res_r['BM25']:.3f}\")\n",
    "        print(f\"Arxiv  : TF={res_a['TF']} | IDF={res_a['IDF']:.3f} | BM25={res_a['BM25']:.3f}\")\n",
    "        if res_r['BM25']>res_a['BM25']:\n",
    "            print(\"Le mot est plus important dans Reddit\")\n",
    "        elif res_r['BM25']<res_a['BM25']:\n",
    "            print(\"Le mot est plus important dans Arxiv\")\n",
    "        else:\n",
    "            print(\"Le mot a la même importance dans les deux corpus\")\n",
    "\n",
    "        counts_r = count_occurrences(reddit.id2doc.values(), mot_sel)\n",
    "        counts_a = count_occurrences(arxiv.id2doc.values(), mot_sel)\n",
    "        plt.figure(figsize=(8,4))\n",
    "        if counts_r:\n",
    "            plt.bar([str(y) for y in sorted(counts_r.keys())], [counts_r[y] for y in sorted(counts_r.keys())], alpha=0.6, label='Reddit')\n",
    "        if counts_a:\n",
    "            plt.bar([str(y) for y in sorted(counts_a.keys())], [counts_a[y] for y in sorted(counts_a.keys())], alpha=0.6, label='Arxiv')\n",
    "        plt.xlabel(\"Année\")\n",
    "        plt.ylabel(\"Occurrences\")\n",
    "        plt.title(f\"Évolution temporelle du mot '{mot_sel}'\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "# -------------------------\n",
    "# Affichage interface\n",
    "# -------------------------\n",
    "btn_analyser.on_click(analyser_mot)\n",
    "display(widgets.VBox([label_titre,type_mot,source,liste_mots,filtre_auteur,filtre_annee,btn_analyser,output]))\n",
    "update_liste()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd210b8-4634-4c51-a198-d64277b1ff72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8399aa73-c796-4190-a4ee-d02e93170144",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Anaconda)",
   "language": "python",
   "name": "conda-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
